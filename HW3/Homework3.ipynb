{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "# Homework 3"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "For this homework you cannot use the python library scikit-learn (sklearn). "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "In the question below, you will construct a document-term matrix, which is a 2-dimensional matrix that describes the frequency of terms (i.e., words) that occur in each document in a collection. In a document-term matrix, rows correspond to documents in the collection and columns correspond to terms. The value in a given cell (i,j) counts the number of times the term j occurs in document i.\n",
                "Reference: https:\/\/en.wikipedia.org\/wiki\/Document-term_matrix"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "# Q1: Feature counting (10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Double-click this box. \n",
                "\n",
                "The text file \"urls.txt\" contains a list of urls for the webpages to be parsed. Each line in the text file corresponds to a url. Use BeautifulSoup to fetch each webpage and parse the text as you did in HW1. Specifically,\n",
                "1. For each webpage document, read the content and do the following:\n",
                "    A. Retrieve all text enclosed in paragraph tags.\n",
                "    B. Convert to lowercase. \n",
                "    C. Strip out punctuation. Note: if you use translate() with string.punctuation, then it may not strip out all characters. Use a regular expression involving \\w to get a list of words from the text.\n",
                "    D. Exlude the stop words given in the file 'stop_words.txt'. \n",
                "    \n",
                "2. Find the set of unique words across all the documents and sort them in lexicographic order. This comprises the \"vocabulary\" of the corpus. Each term in the vocabulary will be a feature in the document-term matrix you will construct next. Do not add the empty string to the vocabulary. \n",
                "\n",
                "3. Create the document-term matrix, where the value of the cell (i,j) in the matrix is the frequency of the term j in document i. The number of columns of the document-term matrix will correspond to the number of unique words in the vocabulary, and the number of rows will correspond to the number of documents (i.e., webpages in urls.txt). Each term is represented by a column of the document-term matrix. Each document is represented by a row of the document-term matrix (ordered by the order of the URLs given in the file). \n",
                "\n",
                "4. Select the most common word from each document to report in the output file \"Q1.txt\" for evaluation.\n",
                "\n",
                "First, report the total vocabulary size Q1.txt.\n",
                "\n",
                "Then, write the most frequent word from each document together with their frequencies in each document in the format below:\n",
                "\n",
                "Vocabulary Size < Vocabulary_Size > < Most Freq Word in Doc 1 > [< Freq in Doc1 > < Freq in Doc2 > ...] < Most Freq Word in Doc 2 > [ < Freq in Doc1 > < Freq in Doc2 > ...] ...\n",
                "\n",
                "Example:\n",
                "\n",
                "Vocabulary Size 1795 data [111 108 0 69 35] ...\n",
                "\n",
                "** Note that your answer should start like this, or at least with something close enough. **\n",
                "    \n",
                "\n",
                "**Don't forget to write your answer to the file with the name given in the text. Please, be careful with the format, put in whitespaces as shown, don't add commas.**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### YOUR CODE HERE\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "# Q2: Grouping features (5)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Double-click this box. \n",
                "\n",
                "Using the document-term matrix from Q1, group the words below that have a common prefix\/stem.\n",
                "\n",
                "i. 'write', 'writing', 'wrote', 'writes', 'written' \n",
                "ii. 'return', 'returns', 'returned', 'returning'\n",
                "iii. 'science', 'sciences', 'scientific', 'scientist', 'scientists'\n",
                "iv. 'use', 'usage', 'used', 'user', 'uses', 'using'\n",
                "v. 'work', 'worker', 'working', 'worked', 'works', 'workers'\n",
                "\n",
                "Find all occurences of the above terms across all the documents. For each group above, sum the frequencies of the associated terms, for each document. Output the results in a file named \"Q2.txt\". \n",
                "\n",
                "The format of the output file is:\n",
                "words_from_i [< summed_freq_in_doc1 >, ...]\n",
                "words_from_ii [< summed_freq_in_doc1 >, ...]\n",
                "...\n",
                "\n",
                "For example, the first line of your file should be:\n",
                "\n",
                "write writing wrote writes written [1, 0, 0, 0, 0]\n",
                "\n",
                "\n",
                "Note how some words will not be present in any document. However, you should list them in the output as well."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### YOUR CODE HERE\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "# Q3: Feature transformation (5)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Double-click this box. \n",
                "\n",
                "1. For every word, find its average frequency across all documents. \n",
                "\n",
                "2. Create a new document-term matrix with the same dimensions as above. For the value of cell (i,j), if the frequency of word j in document i is greater than the average frequency of word j, then set the value to +1, otherwise set it to -1. \n",
                "\n",
                "4. Select a subset (as described below) of this transformed document-term matrix to report in the output file \"Q3.txt\" for evaluation\n",
                "\n",
                "For the words: 'data', 'companies', 'business', 'action', 'mining', 'science':\n",
                "Write the words along with their corresponding values for each document. \n",
                "\n",
                "The format of the output file is a line corresponding to one of the target words, in the format\n",
                "\n",
                "word < avg > < [  list of 1,-1 with respect to document  ] >\n",
                "\n",
                "Please, write the words in the order 'data', 'companies', 'business', 'action', 'mining', 'science'.\n",
                "\n",
                "For example, the first line of your file should be\n",
                "\n",
                "data 64.6 [1, 1, -1, 1, -1]\n",
                "...\n",
                "\n",
                "The results above are for the first three webpage urls given in the file \"urls.txt\". The values should be listed in the order of the urls given in \"urls.txt\".\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### YOUR CODE HERE\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "# Q4: Bigram features (10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Double-click this box. \n",
                "\n",
                "A bigram is a sequence of two adjacent words from a string of words. \n",
                "For example, consider the following sentence:\n",
                "    \"a screaming comes across the sky\"\n",
                "The bigrams in this sentence would be\n",
                "1. a screaming\n",
                "2. screaming comes\n",
                "3. comes across\n",
                "4. across the\n",
                "5. the sky"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Double-click this box. \n",
                "\n",
                "1. For each webpage document, read the content and do the following:\n",
                "    A. Parse all paragraph text, convert to lowercase, strip out punctuation, and tokenize based on whitespace separation as for Q1 (i.e. steps A-D).\n",
                "    B. For this question, do not exclude the stop words. \n",
                "    C. Compute a list of bigrams for each document, where each bigram is a concatenation of two adjacent words. To make it easy, you shall consider adjacency words accross paragraphs, i.e. the last word of a paragraph is adjacent to the first word of the next paragraph and so on.\n",
                "    Example:\n",
                "    If the list of words found after tokenizing is ['screaming', 'comes', 'across', 'sky'], \n",
                "    then the list of bigrams would be ['screamingcomes', 'comesacross', 'acrosssky']\n",
                "\n",
                "2. Find the set of unique bigrams across all the documents and sort them in lexicographic order. This will form the vocabulary of bigrams. \n",
                "\n",
                "3. Find the set of bigrams that occur in **all** documents. \n",
                "\n",
                "4. Output the results for evaluation in the file \"Q4.txt\".\n",
                "\n",
                "In the file \"Q4.txt\", report the number of bigrams found in step 2 as the first line, followed by each bigram (listed in lexicographic order) from step 3 on a new line.\n",
                "\n",
                "The format of the output file is:\n",
                "\n",
                "Bigram Size < Bigram Size >\n",
                "\n",
                "< first_word_bigram1 > < second_word_bigram1 >\n",
                "\n",
                "< first_word_bigram2 > < second_word_bigram2 >\n",
                "\n",
                "...\n",
                "\n",
                "\n",
                "For example, your output should start with\n",
                "\n",
                "Bigram Size 5453\n",
                "\n",
                "in order\n",
                "\n",
                "...\n",
                "\n",
                "** As long as you get a close enough vocab size, we will consider your answer **\n",
                "\n",
                "The results above are for the first three webpage urls given in the file \"urls.txt\". (This is only an example output.)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### YOUR CODE HERE\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 [3.6]",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text\/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}