{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unix Command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract fist 500,000 lines into \"test_set_tweets_500000.txt \" \n",
    "!head -500000 test_set_tweets.txt > test_set_tweets_500000.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hashtags words and store them into \"hashtags_500000.txt\"\n",
    "!grep -P -o \"#[^ \\t]+\" test_set_tweets_500000.txt > hashtags_500000.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#confession.\r\n",
      "#worstfeeling.:\r\n",
      "#FF\r\n",
      "#mm.\r\n",
      "#niggas.\r\n",
      "#dontjudgeme\r\n",
      "#nowplaying.\r\n",
      "#nowplaying.\r\n",
      "#PersonalBelief\r\n",
      "#imjustsayin\r\n"
     ]
    }
   ],
   "source": [
    "# First 10 lines of \"hashtags_500000.txt\"\n",
    "!head -10 hashtags_500000.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip out punctuation and convert uppercase to lowercase\n",
    "!sed 's/#//g' hashtags_500000.txt | sed 's/[^a-zA-Z]//g' | sed -e 's/\\(.*\\)/\\L\\1/' > keywords_500000.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate frequence of hashtags and store the result into \"result_hastags_500000.txt\"\n",
    "!sort keywords_500000.txt | uniq --count | sort -nr > result_hastags_500000.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3581 ff\r\n",
      "   1809 nowplaying\r\n",
      "   1402 fb\r\n",
      "   1361 \r\n",
      "   1029 mm\r\n",
      "    686 fail\r\n",
      "    622 random\r\n",
      "    591 haiti\r\n",
      "    529 shoutout\r\n",
      "    457 followfriday\r\n"
     ]
    }
   ],
   "source": [
    "# Result of top 10 hashtags\n",
    "!head -10 result_hastags_500000.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/sh\r\n",
      "sed 's/#//g' hashtags_500000.txt | sed 's/[^a-zA-Z]//g' | sed -e 's/\\(.*\\)/\\L\\1/' > keywords_500000.txt\r\n",
      "sort keywords_500000.txt | uniq --count | sort -nr > result_hastags_500000.txt\r\n",
      "head -10 result_hastags_500000.txt\r\n"
     ]
    }
   ],
   "source": [
    "# Shell script of 1.1\n",
    "!cat 1_1.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3581 ff\r\n",
      "   1809 nowplaying\r\n",
      "   1402 fb\r\n",
      "   1361 \r\n",
      "   1029 mm\r\n",
      "    686 fail\r\n",
      "    622 random\r\n",
      "    591 haiti\r\n",
      "    529 shoutout\r\n",
      "    457 followfriday\r\n",
      "0.33user 0.01system 0:00.25elapsed 133%CPU (0avgtext+0avgdata 6436maxresident)k\r\n",
      "0inputs+2232outputs (0major+2558minor)pagefaults 0swaps\r\n"
     ]
    }
   ],
   "source": [
    "# Runtime of 1.1 using Unix command\n",
    "!time bash 1_1.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract fist 250,000 lines into \"training_set_tweets_250000.txt\" \n",
    "!head -250000 training_set_tweets.txt > training_set_tweets_250000.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60730027\t6320951896\t@thediscovietnam coo.  thanks. just dropped you a line.\t2009-12-03 18:41:07\r",
      "\r\n",
      "60730027\t6320673258\t@thediscovietnam shit it ain't lettin me DM you back, what's your email?\t2009-12-03 18:31:01\r",
      "\r\n",
      "60730027\t6319871652\t@thediscovietnam hey cody, quick question...can you dm me?\t2009-12-03 18:01:51\r",
      "\r\n",
      "60730027\t6318151501\t@smokinvinyl dang.  you need anything?  I got some left over meds!\t2009-12-03 17:00:16\r",
      "\r\n",
      "60730027\t6317932721\tmaybe i'm late in the game on this one, but this lowender vst is making my apt rumble!\t2009-12-03 16:52:36\r",
      "\r\n",
      "60730027\t6317701252\ti really hope A.I. makes the most of this second chance in philly. i'm glad he's goin home.\t2009-12-03 16:44:37\r",
      "\r\n",
      "60730027\t6315879930\t@smokinvinyl danny boy! wanna check out d-nice at the afex 1 year tonight?  we could pre-game at mine and walk over.\t2009-12-03 15:39:10\r",
      "\r\n",
      "60730027\t6314008277\t...and if you have ppl that you care about, make sure to let them know. life is too short to lose friends over bullshit.  peace and love.\t2009-12-03 14:26:33\r",
      "\r\n",
      "60730027\t6313959103\t...that shit weighs heavy on me.  take responsibility for your life. I don't blame anyone for where I am in this world...\t2009-12-03 14:24:40\r",
      "\r\n",
      "60730027\t6313919319\t...including his last failed relationship.  and while I know that none of it is grounded in reality, and I actually am worried about him...\t2009-12-03 14:23:07\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# First 10 lines in \"training_set_tweets_250000.txt\"\n",
    "!head -10 training_set_tweets_250000.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the first 500,000 lines from \"test_set_tweets_500000.txt\" and the first 250,000 lines from \"training_set\n",
    "# _tweets_250000.txt\" into \"tweets.txt\"\n",
    "!cat test_set_tweets_500000.txt training_set_tweets_250000.txt > tweets.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750000 tweets.txt\r\n"
     ]
    }
   ],
   "source": [
    "# Number of lines in \"tweets.txt\"\n",
    "!wc -l tweets.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract username and store them into \"tweets_username.txt\"\n",
    "!grep -P -o \"@[^ \\t]+\" tweets.txt > tweets_username.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@LovelyJ_Janelle\r\n",
      "@Iam_MarkyMark\r\n",
      "@Iam_MarkyMark\r\n",
      "@Iam_MarkyMark\r\n",
      "@seanlamar919\r\n",
      "@TRenee3\r\n",
      "@LovelyJ_Janelle\r\n",
      "@seanlamar919\r\n",
      "@seanlamar919\r\n",
      "@Iam_MarkyMark:\r\n"
     ]
    }
   ],
   "source": [
    "# First 10 lines in \"tweets_username.txt\"\n",
    "!head -10 tweets_username.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate frequence of hashtags and store the result into \"result_username_750000.txt\"\n",
    "!sort tweets_username.txt | uniq --count | sort -nr > result_username_750000.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1234 @RevRunWisdom:\r\n",
      "    939 @listensto\r\n",
      "    525 @DonnieWahlberg\r\n",
      "    441 @OGmuscles\r\n",
      "    419 @addthis\r\n",
      "    411 @breatheitin\r\n",
      "    354 @justinbieber\r\n",
      "    347 @MAV25\r\n",
      "    303 @karlievoice\r\n",
      "    291 @mtgcolorpie\r\n"
     ]
    }
   ],
   "source": [
    "# Result of top 10 usernames\n",
    "! head -10 result_username_750000.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/sh\r\n",
      "grep -P -o \"@[^ \\t]+\" tweets.txt > tweets_username.txt\r\n",
      "sort tweets_username.txt | uniq --count | sort -nr > result_username_750000.txt\r\n",
      "head -10 result_username_750000.txt\r\n"
     ]
    }
   ],
   "source": [
    "# Shell script for 1.2 (1)\n",
    "!cat 1_2.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1234 @RevRunWisdom:\r\n",
      "    939 @listensto\r\n",
      "    525 @DonnieWahlberg\r\n",
      "    441 @OGmuscles\r\n",
      "    419 @addthis\r\n",
      "    411 @breatheitin\r\n",
      "    354 @justinbieber\r\n",
      "    347 @MAV25\r\n",
      "    303 @karlievoice\r\n",
      "    291 @mtgcolorpie\r\n",
      "2.06user 0.04system 0:01.12elapsed 187%CPU (0avgtext+0avgdata 55920maxresident)k\r\n",
      "0inputs+25128outputs (0major+16292minor)pagefaults 0swaps\r\n"
     ]
    }
   ],
   "source": [
    "# Runtime of 1.2 (1) using Unix command\n",
    "!time bash 1_2.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract username and store them into \"tweets_username.txt\"\n",
    "!grep -P -o \"#[^ \\t]+#[^ \\t]+\" tweets.txt > tweets_twohashtags.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#trueshit...#scaryshit...but\r\n",
      "#!%#$^!@%&\r\n",
      "#honey.......#imjussayn\r\n",
      "#pause.....#megapause\r\n",
      "#9:#Virtualization\r\n",
      "#8:#Offshore\r\n",
      "#thatisall--#agree\r\n",
      "#FF--#FF\r\n",
      "#LENT....#SMH\r\n",
      "#UCanTakeTheKidOutHoodBut#UCanTakeTheKidOutHoodBut#UCanTakeTheKidOutHoodBut#UCanTakeTheKidOutHoodBut#UCanTakeTheKidOutHoodBut\r\n"
     ]
    }
   ],
   "source": [
    "# First 10 lines in \"tweets_twohashtags.txt\"\n",
    "!head -10 tweets_twohashtags.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate frequence of hashtags and store the result into \"result_twohastags_750000.txt\"\n",
    "!sort tweets_twohashtags.txt | uniq --count | sort -nr > result_twohashtags_750000.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 #affiliate#marketing\r\n",
      "      5 #zewdy#zewdy\r\n",
      "      5 #BGC#BGC\r\n",
      "      5 ####\r\n",
      "      4 #??PFoundersday#??PFoundersday\r\n",
      "      4 #Celebrity,#Philanthropy\r\n",
      "      3 #AKA#AKA\r\n",
      "      3 #39;What&#39;s\r\n",
      "      3 #39;streaming&#39;\r\n",
      "      3 #39;Green&#39;\r\n"
     ]
    }
   ],
   "source": [
    "# Result of top 10 tweets that have at least two hashtags\n",
    "! head -10 result_twohashtags_750000.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/sh\r\n",
      "grep -P -o \"#[^ \\t]+#[^ \\t]+\" tweets.txt > tweets_twohashtags.txt\r\n",
      "sort tweets_twohashtags.txt | uniq --count | sort -nr > result_twohashtags_750000.txt\r\n",
      "head -10 result_twohashtags_750000.txt\r\n"
     ]
    }
   ],
   "source": [
    "# Shell script for 1.2 (2)\n",
    "!cat 1_3.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 #affiliate#marketing\r\n",
      "      5 #zewdy#zewdy\r\n",
      "      5 #BGC#BGC\r\n",
      "      5 ####\r\n",
      "      4 #??PFoundersday#??PFoundersday\r\n",
      "      4 #Celebrity,#Philanthropy\r\n",
      "      3 #AKA#AKA\r\n",
      "      3 #39;What&#39;s\r\n",
      "      3 #39;streaming&#39;\r\n",
      "      3 #39;Green&#39;\r\n",
      "0.17user 0.01system 0:00.18elapsed 100%CPU (0avgtext+0avgdata 3108maxresident)k\r\n",
      "0inputs+48outputs (0major+828minor)pagefaults 0swaps\r\n"
     ]
    }
   ],
   "source": [
    "# Runtime of 1.2 (2) using Unix command\n",
    "!time bash 1_3.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract fist 250,000 lines into \"training_set_tweets_250000.txt\" \n",
    "!head -500000　edges.csv > edges_500000.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap order is userID is larger than followerID and store the result into \"edges_500000_dup.csv\"\n",
    "!awk -F \",\" '{if($1<$2) printf(\"%d,%d\\n\", $1,$2);if($1>$2) printf(\"%d,%d\\n\", $2,$1)}' edges_500000.csv > edges_500000_dup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find pairs that appear twice (reciprocal follower) and store it into \"output.csv\"\n",
    "!sort edges_500000_dup.csv | uniq --count --repeated > output.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100591,100721\r\n",
      "100721,100591\r\n",
      "102898,122546\r\n",
      "122546,102898\r\n",
      "13232,18205\r\n",
      "18205,13232\r\n",
      "13232,63255\r\n",
      "63255,13232\r\n",
      "134409,134410\r\n",
      "134410,134409\r\n",
      "135546,135684\r\n",
      "135684,135546\r\n",
      "15574,15926\r\n",
      "15926,15574\r\n",
      "192865,192899\r\n",
      "192899,192865\r\n",
      "19628,19821\r\n",
      "19821,19628\r\n",
      "19628,20033\r\n",
      "20033,19628\r\n",
      "201063,40997\r\n",
      "40997,201063\r\n",
      "201078,201607\r\n",
      "201607,201078\r\n",
      "22196,76473\r\n",
      "76473,22196\r\n",
      "23503,41422\r\n",
      "41422,23503\r\n",
      "31866,32002\r\n",
      "32002,31866\r\n",
      "32173,32452\r\n",
      "32452,32173\r\n",
      "33099,62167\r\n",
      "62167,33099\r\n",
      "33884,34046\r\n",
      "34046,33884\r\n",
      "33884,34101\r\n",
      "34101,33884\r\n",
      "3682,5276\r\n",
      "5276,3682\r\n",
      "40704,40997\r\n",
      "40997,40704\r\n",
      "40704,41039\r\n",
      "41039,40704\r\n",
      "40997,41039\r\n",
      "41039,40997\r\n",
      "40997,62623\r\n",
      "62623,40997\r\n",
      "58783,58875\r\n",
      "58875,58783\r\n",
      "60887,70696\r\n",
      "70696,60887\r\n",
      "63255,65435\r\n",
      "65435,63255\r\n",
      "65411,65435\r\n",
      "65435,65411\r\n",
      "65435,93260\r\n",
      "93260,65435\r\n",
      "70696,70772\r\n",
      "70772,70696\r\n",
      "78182,78464\r\n",
      "78464,78182\r\n",
      "80092,80096\r\n",
      "80096,80092\r\n",
      "89222,89350\r\n",
      "89350,89222\r\n",
      "93260,93427\r\n",
      "93427,93260\r\n"
     ]
    }
   ],
   "source": [
    "# Report reciprocal followers\n",
    "!grep -E -o \" [0-9]+,[0-9]+$\" output.csv | awk -F \",\" '{printf(\"%d,%d\\n%d,%d\\n\", $1,$2, $2,$1)}' > result_reciprocalFollowers.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\r\n"
     ]
    }
   ],
   "source": [
    "# Number of reciprocal followers: 34 * 2\n",
    "!grep -E -o \" [0-9]+,[0-9]+$\" output.csv | awk -F \",\" '{printf(\"%d,%d\\n%d,%d\\n\", $1,$2, $2,$1)}' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/sh\r\n",
      "awk -F \",\" '{if($1<$2) printf(\"%d,%d\\n\", $1,$2);if($1>$2) printf(\"%d,%d\\n\", $2,$1)}' edges_500000.csv > edges_500000_dup.csv\r\n",
      "sort edges_500000_dup.csv | uniq --count --repeated > output.csv\r\n",
      "grep -E -o \" [0-9]+,[0-9]+$\" output.csv | awk -F \",\" '{printf(\"%d,%d\\t%d,%d\\t\", $1,$2, $2,$1)}'\r\n",
      "echo \"\\n\"\r\n"
     ]
    }
   ],
   "source": [
    "# Shell script for ２\n",
    "!cat 2.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100591,100721\t100721,100591\t102898,122546\t122546,102898\t13232,18205\t18205,13232\t13232,63255\t63255,13232\t134409,134410\t134410,134409\t135546,135684\t135684,135546\t15574,15926\t15926,15574\t192865,192899\t192899,192865\t19628,19821\t19821,19628\t19628,20033\t20033,19628\t201063,40997\t40997,201063\t201078,201607\t201607,201078\t22196,76473\t76473,22196\t23503,41422\t41422,23503\t31866,32002\t32002,31866\t32173,32452\t32452,32173\t33099,62167\t62167,33099\t33884,34046\t34046,33884\t33884,34101\t34101,33884\t3682,5276\t5276,3682\t40704,40997\t40997,40704\t40704,41039\t41039,40704\t40997,41039\t41039,40997\t40997,62623\t62623,40997\t58783,58875\t58875,58783\t60887,70696\t70696,60887\t63255,65435\t65435,63255\t65411,65435\t65435,65411\t65435,93260\t93260,65435\t70696,70772\t70772,70696\t78182,78464\t78464,78182\t80092,80096\t80096,80092\t89222,89350\t89350,89222\t93260,93427\t93427,93260\t\\n\r\n",
      "1.53user 0.03system 0:00.71elapsed 219%CPU (0avgtext+0avgdata 55792maxresident)k\r\n",
      "0inputs+13344outputs (0major+14257minor)pagefaults 0swaps\r\n"
     ]
    }
   ],
   "source": [
    "# Runtime of 2 using Unix command\n",
    "!time bash 2.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
