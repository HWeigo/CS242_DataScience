{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Finding Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read txt\n",
    "with open(\"test_set_tweets.txt\",\"r\", encoding='utf-8') as file:\n",
    "    lines = [next(file) for x in range(500000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['confession']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extractHashtags(string):\n",
    "    pattern = re.compile(r\"#(\\S+)\")\n",
    "    strs = re.findall(pattern, string)\n",
    "    \n",
    "    pattern = re.compile('[^a-zA-Z]')\n",
    "    output = []\n",
    "    for i in strs:\n",
    "        output.append(pattern.sub('', i.lower()))\n",
    "    return output\n",
    "\n",
    "# Example:\n",
    "extractHashtags(\"22077441\t10470781081\t#confession.   I can't live with my mama!!! Especially if I don't have my own car!\t2010-03-14 09:21:58\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('confession', 1)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mapper_hashtags_line(line):\n",
    "    words = extractHashtags(line)\n",
    "    output = []\n",
    "    for word in words:\n",
    "        if word:\n",
    "            output.append((word,1))\n",
    "    return output\n",
    "\n",
    "# Example:\n",
    "mapper_hashtags_line(\"22077441\t10470781081\t#confession.   I can't live with my mama!!! Especially if I don't have my own car!\t2010-03-14 09:21:58\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('john', 1), ('jerry', 1), ('tom', 1), ('jerry', 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mapper_hashtags(lines):\n",
    "    output = []\n",
    "    for line in lines:\n",
    "        list = mapper_hashtags_line(line)\n",
    "        if list:\n",
    "            output += list\n",
    "    return output\n",
    "\n",
    "#Example:\n",
    "test = [\"#John. 2010\", \"#Jerry 2011\", \"#Tom 2012\", \"#Jerry 2013\"]\n",
    "mapper_hashtags(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'john': [1], 'jerry': [1, 1], 'tom': [1]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def combiner_heshtags(mapper_output):\n",
    "    groups = {} # group by key values\n",
    "    for item in mapper_output:\n",
    "        k = item[0]\n",
    "        v = item[1]\n",
    "        if k not in groups:\n",
    "            groups[k] = [v]\n",
    "        else:\n",
    "            groups[k].append(v) \n",
    "    return groups\n",
    "\n",
    "#Example:\n",
    "combiner_heshtags(mapper_hashtags(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('jerry', 14)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reducer_heshtags(keyWord, counts):\n",
    "    return (keyWord, sum(counts))\n",
    "\n",
    "reducer_heshtags( 'jerry',[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_heshtags(lines):\n",
    "    groups = combiner_heshtags(mapper_hashtags(lines))\n",
    "    output = [reducer_heshtags(k,v) for k,v in groups.items()] \n",
    "    output.sort()\n",
    "    return output\n",
    "\n",
    "hashtags_freq = execute_heshtags(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ff', 3581), ('nowplaying', 1809), ('fb', 1402), ('mm', 1029), ('fail', 686), ('random', 622), ('haiti', 591), ('shoutout', 529), ('followfriday', 457), ('musicmonday', 452)]\n"
     ]
    }
   ],
   "source": [
    "def Sort(orig): \n",
    "\n",
    "    orig.sort(key = lambda x: x[1], reverse = True) \n",
    "    return orig \n",
    " \n",
    "print(Sort(hashtags_freq)[:10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ff', 3581), ('nowplaying', 1809), ('fb', 1402), ('mm', 1029), ('fail', 686), ('random', 622), ('haiti', 591), ('shoutout', 529), ('followfriday', 457), ('musicmonday', 452)]\n",
      "Time:  1.6265050999999175\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "hashtags_freq = execute_heshtags(lines)\n",
    "print(Sort(hashtags_freq)[:10]) \n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion:\n",
    "As is shown above, it takes about **1.63 sec** to find the top 10 hashtags using map reduce approach in Python, while it only takes **0.25 sec** using Unix command. I think this is because Python is an interpreted language and it runs much slower than shell command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read txt\n",
    "with open(\"tweets.txt\",\"r\", encoding='utf-8') as file:\n",
    "    lines = [next(file) for x in range(750000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Confession.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extractUsernames(string):\n",
    "    pattern = re.compile(r\"@(\\S+)\")\n",
    "    strs = re.findall(pattern, string)\n",
    "    \n",
    "    output = []\n",
    "    for i in strs:\n",
    "        output.append(i)\n",
    "    return output\n",
    "\n",
    "# Example:\n",
    "extractUsernames(\"22077441\t10470781081\t@Confession.   I can't live with my mama!!! Especially if I don't have my own car!\t2010-03-14 09:21:58\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Confession.', 1)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mapper_usernames_line(line):\n",
    "    words = extractUsernames(line)\n",
    "    output = []\n",
    "    for word in words:\n",
    "        if word:\n",
    "            output.append((word,1))\n",
    "    return output\n",
    "\n",
    "# Example:\n",
    "mapper_usernames_line(\"22077441\t10470781081\t@Confession.   I can't live with my mama!!! Especially if I don't have my own car!\t2010-03-14 09:21:58\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('John.', 1), ('Jerry', 1), ('Tom', 1), ('Jerry', 1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mapper_usernames(lines):\n",
    "    output = []\n",
    "    for line in lines:\n",
    "        list = mapper_usernames_line(line)\n",
    "        if list:\n",
    "            output += list\n",
    "    return output\n",
    "\n",
    "#Example:\n",
    "test = [\"@John. 2010\", \"@Jerry 2011\", \"@Tom 2012\", \"@Jerry 2013\"]\n",
    "mapper_usernames(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'John.': [1], 'Jerry': [1, 1], 'Tom': [1]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def combiner_usernames(mapper_output):\n",
    "    groups = {} # group by key values\n",
    "    for item in mapper_output:\n",
    "        k = item[0]\n",
    "        v = item[1]\n",
    "        if k not in groups:\n",
    "            groups[k] = [v]\n",
    "        else:\n",
    "            groups[k].append(v) \n",
    "    return groups\n",
    "\n",
    "#Example:\n",
    "combiner_usernames(mapper_usernames(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('jerry', 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reducer_usernames(keyWord, counts):\n",
    "    return (keyWord, sum(counts))\n",
    "\n",
    "reducer_usernames( 'jerry',[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_usernames(lines):\n",
    "    groups = combiner_usernames(mapper_usernames(lines))\n",
    "    output = [reducer_usernames(k,v) for k,v in groups.items()] \n",
    "    output.sort()\n",
    "    return output\n",
    "\n",
    "usernames_freq = execute_usernames(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('RevRunWisdom:', 1234), ('listensto', 939), ('DonnieWahlberg', 525), ('OGmuscles', 441), ('addthis', 429), ('breatheitin', 411), ('justinbieber', 354), ('MAV25', 347), ('karlievoice', 305), ('mtgcolorpie', 291)]\n"
     ]
    }
   ],
   "source": [
    "def Sort(orig): \n",
    "\n",
    "    orig.sort(key = lambda x: x[1], reverse = True) \n",
    "    return orig \n",
    " \n",
    "print(Sort(usernames_freq)[:10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('RevRunWisdom:', 1234), ('listensto', 939), ('DonnieWahlberg', 525), ('OGmuscles', 441), ('addthis', 429), ('breatheitin', 411), ('justinbieber', 354), ('MAV25', 347), ('karlievoice', 305), ('mtgcolorpie', 291)]\n",
      "Time:  3.0066348999999946\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "usernames_freq = execute_usernames(lines)\n",
    "print(Sort(usernames_freq)[:10]) \n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion:\n",
    "As is shown above, it takes about **3.01 sec** to find the top 10 hashtags using map reduce approach in Python, while it only takes **1.12 sec** using Unix command. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[]]\n",
      "['#Confession#Disappointment#Desperation.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extractTwohashtags(string):\n",
    "    pattern = re.compile(r\"#\\S+#\\S+\")\n",
    "    strs = re.search(pattern, string)\n",
    "    output = []\n",
    "    if strs:\n",
    "        output.append(strs.group(0))\n",
    "    else:\n",
    "        output.append([])\n",
    "    return output\n",
    "\n",
    "# Example:\n",
    "print(extractTwohashtags(\"22077441\t10470781081\t#Confession.   I can't live with my mama!!! Especially if I don't have my own car!\t2010-03-14 09:21:58\"))\n",
    "print(extractTwohashtags(\"22077441\t10470781081\t#Confession#Disappointment#Desperation.   I can't live with my mama!!! Especially if I don't have my own car!\t2010-03-14 09:21:58\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#Confession#Disappointment', 1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mapper_twohashtags_line(line):\n",
    "    words = extractTwohashtags(line)\n",
    "    output = []\n",
    "    for word in words:\n",
    "        if word:\n",
    "            output.append((word,1))\n",
    "    return output\n",
    "\n",
    "# Example:\n",
    "mapper_twohashtags_line(\"22077441\t10470781081\t#Confession#Disappointment   I can't live with my mama!!! Especially if I don't have my own car!\t2010-03-14 09:21:58\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#John.#2010', 1), ('#Jerry#2013', 1), ('#Jerry#2013', 1)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mapper_twohashtags(lines):\n",
    "    output = []\n",
    "    for line in lines:\n",
    "        list = mapper_twohashtags_line(line)\n",
    "        if list:\n",
    "            output += list\n",
    "    return output\n",
    "\n",
    "#Example:\n",
    "test = [\"#John.#2010\", \"#Jerry#2013\", \"#Tom2012\", \"#Jerry#2013\"]\n",
    "mapper_twohashtags(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'#John.#2010': [1], '#Jerry#2013': [1, 1]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def combiner_twohashtags(mapper_output):\n",
    "    groups = {} # group by key values\n",
    "    for item in mapper_output:\n",
    "        k = item[0]\n",
    "        v = item[1]\n",
    "        if k not in groups:\n",
    "            groups[k] = [v]\n",
    "        else:\n",
    "            groups[k].append(v) \n",
    "    return groups\n",
    "\n",
    "#Example:\n",
    "combiner_twohashtags(mapper_twohashtags(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('jerry', 14)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reducer_twohashtags(keyWord, counts):\n",
    "    return (keyWord, sum(counts))\n",
    "\n",
    "reducer_twohashtags( 'jerry',[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_twohashtags(lines):\n",
    "    groups = combiner_twohashtags(mapper_twohashtags(lines))\n",
    "    output = [reducer_twohashtags(k,v) for k,v in groups.items()] \n",
    "    output.sort()\n",
    "    return output\n",
    "\n",
    "twohashtags_freq = execute_twohashtags(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('#affiliate#marketing', 8), ('####', 5), ('#Celebrity,#Philanthropy', 4), ('#39;Green&#39;', 3), ('#39;What&#39;s', 3), ('#39;streaming&#39;', 3), ('#??PFoundersday#??PFoundersday', 3), ('#39;A&#39;', 2), ('#39;SNL&#39;:', 2), ('#39;Twilight&#39;', 2)]\n"
     ]
    }
   ],
   "source": [
    "def Sort(orig): \n",
    "\n",
    "    orig.sort(key = lambda x: x[1], reverse = True) \n",
    "    return orig \n",
    " \n",
    "print(Sort(twohashtags_freq)[:10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('#affiliate#marketing', 8), ('####', 5), ('#Celebrity,#Philanthropy', 4), ('#39;Green&#39;', 3), ('#39;What&#39;s', 3), ('#39;streaming&#39;', 3), ('#??PFoundersday#??PFoundersday', 3), ('#39;A&#39;', 2), ('#39;SNL&#39;:', 2), ('#39;Twilight&#39;', 2)]\n",
      "Time:  1.9740761999999847\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "usernames_freq = execute_twohashtags(lines)\n",
    "print(Sort(twohashtags_freq)[:10]) \n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion:\n",
    "As is shown above, it takes about **1.97 sec** to find the top 10 hashtags using map reduce approach in Python, while it only takes **0.18 sec** using Unix command. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Finding Reciprocal Followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "edges_orig = pd.read_csv(\"./Twitter-dataset/data/edges.csv\")\n",
    "edges = edges_orig.head(500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_test = edges_orig.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 8762940],\n",
       " [1, 8762941],\n",
       " [1, 688136],\n",
       " [1, 8762942],\n",
       " [3, 718952],\n",
       " [3, 3109655],\n",
       " [3, 562897],\n",
       " [3, 6],\n",
       " [3, 7],\n",
       " [3, 12852],\n",
       " [3, 90259],\n",
       " [3, 8762941],\n",
       " [3, 645510],\n",
       " [3, 427258],\n",
       " [3, 45567],\n",
       " [3, 1374301],\n",
       " [3, 38253],\n",
       " [3, 79994],\n",
       " [3, 16],\n",
       " [3, 9]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mapper_reciprocal(df):\n",
    "    return list(map(list, df.values))\n",
    "        \n",
    "# Example:\n",
    "mapper_reciprocal(edges_test)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combiner_reciprocal(mapper_output):\n",
    "    groups = {} # group by key values\n",
    "    for item in mapper_output:\n",
    "        k = item[0]\n",
    "        v = item[1]\n",
    "        if k not in groups:\n",
    "            groups[k] = [v]\n",
    "        else:\n",
    "            groups[k].append(v) \n",
    "    return groups\n",
    "\n",
    "# Example:\n",
    "# combiner_reciprocal(mapper_reciprocal(edges_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reducer_reciprocal(userID, followingID, group):\n",
    "    if followingID in group:\n",
    "        if userID in group[followingID]:\n",
    "            return (userID, followingID)\n",
    "        \n",
    "#Example:\n",
    "g = {1:[2,3],2:[1],3:[2,4]}\n",
    "reducer_reciprocal(1, 2, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_reciprocal(edges):\n",
    "    map_reciprocal = mapper_reciprocal(edges)\n",
    "    groups = combiner_reciprocal(map_reciprocal)\n",
    "    output = []\n",
    "    for users in map_reciprocal:\n",
    "            pair =  reducer_reciprocal(users[0],users[1], groups)\n",
    "            if pair:\n",
    "                output.append(pair) \n",
    "    output.sort()\n",
    "    return output\n",
    "\n",
    "output = execute_reciprocal(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  1.2204441000000088\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "execute_reciprocal(edges)\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>followerID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3682</td>\n",
       "      <td>5276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5276</td>\n",
       "      <td>3682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13232</td>\n",
       "      <td>18205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13232</td>\n",
       "      <td>63255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15574</td>\n",
       "      <td>15926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15926</td>\n",
       "      <td>15574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18205</td>\n",
       "      <td>13232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19628</td>\n",
       "      <td>19821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19628</td>\n",
       "      <td>20033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19821</td>\n",
       "      <td>19628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20033</td>\n",
       "      <td>19628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>22196</td>\n",
       "      <td>76473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>23503</td>\n",
       "      <td>41422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>31866</td>\n",
       "      <td>32002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>32002</td>\n",
       "      <td>31866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>32173</td>\n",
       "      <td>32452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>32452</td>\n",
       "      <td>32173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>33099</td>\n",
       "      <td>62167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>33884</td>\n",
       "      <td>34046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>33884</td>\n",
       "      <td>34101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>34046</td>\n",
       "      <td>33884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>34101</td>\n",
       "      <td>33884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>40704</td>\n",
       "      <td>40997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>40704</td>\n",
       "      <td>41039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>40997</td>\n",
       "      <td>40704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>40997</td>\n",
       "      <td>41039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>40997</td>\n",
       "      <td>62623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>40997</td>\n",
       "      <td>201063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>41039</td>\n",
       "      <td>40704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>41039</td>\n",
       "      <td>40997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>65411</td>\n",
       "      <td>65435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>65435</td>\n",
       "      <td>63255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>65435</td>\n",
       "      <td>65411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>65435</td>\n",
       "      <td>93260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>70696</td>\n",
       "      <td>60887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>70696</td>\n",
       "      <td>70772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>70772</td>\n",
       "      <td>70696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>76473</td>\n",
       "      <td>22196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>78182</td>\n",
       "      <td>78464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>78464</td>\n",
       "      <td>78182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>80092</td>\n",
       "      <td>80096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>80096</td>\n",
       "      <td>80092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>89222</td>\n",
       "      <td>89350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>89350</td>\n",
       "      <td>89222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>93260</td>\n",
       "      <td>65435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>93260</td>\n",
       "      <td>93427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>93427</td>\n",
       "      <td>93260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>100591</td>\n",
       "      <td>100721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>100721</td>\n",
       "      <td>100591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>102898</td>\n",
       "      <td>122546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>122546</td>\n",
       "      <td>102898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>134409</td>\n",
       "      <td>134410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>134410</td>\n",
       "      <td>134409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>135546</td>\n",
       "      <td>135684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>135684</td>\n",
       "      <td>135546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>192865</td>\n",
       "      <td>192899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>192899</td>\n",
       "      <td>192865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>201063</td>\n",
       "      <td>40997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>201078</td>\n",
       "      <td>201607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>201607</td>\n",
       "      <td>201078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    userID  followerID\n",
       "0     3682        5276\n",
       "1     5276        3682\n",
       "2    13232       18205\n",
       "3    13232       63255\n",
       "4    15574       15926\n",
       "5    15926       15574\n",
       "6    18205       13232\n",
       "7    19628       19821\n",
       "8    19628       20033\n",
       "9    19821       19628\n",
       "10   20033       19628\n",
       "11   22196       76473\n",
       "12   23503       41422\n",
       "13   31866       32002\n",
       "14   32002       31866\n",
       "15   32173       32452\n",
       "16   32452       32173\n",
       "17   33099       62167\n",
       "18   33884       34046\n",
       "19   33884       34101\n",
       "20   34046       33884\n",
       "21   34101       33884\n",
       "22   40704       40997\n",
       "23   40704       41039\n",
       "24   40997       40704\n",
       "25   40997       41039\n",
       "26   40997       62623\n",
       "27   40997      201063\n",
       "28   41039       40704\n",
       "29   41039       40997\n",
       "..     ...         ...\n",
       "38   65411       65435\n",
       "39   65435       63255\n",
       "40   65435       65411\n",
       "41   65435       93260\n",
       "42   70696       60887\n",
       "43   70696       70772\n",
       "44   70772       70696\n",
       "45   76473       22196\n",
       "46   78182       78464\n",
       "47   78464       78182\n",
       "48   80092       80096\n",
       "49   80096       80092\n",
       "50   89222       89350\n",
       "51   89350       89222\n",
       "52   93260       65435\n",
       "53   93260       93427\n",
       "54   93427       93260\n",
       "55  100591      100721\n",
       "56  100721      100591\n",
       "57  102898      122546\n",
       "58  122546      102898\n",
       "59  134409      134410\n",
       "60  134410      134409\n",
       "61  135546      135684\n",
       "62  135684      135546\n",
       "63  192865      192899\n",
       "64  192899      192865\n",
       "65  201063       40997\n",
       "66  201078      201607\n",
       "67  201607      201078\n",
       "\n",
       "[68 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "follower_graph = pd.DataFrame(output, columns =['userID', 'followerID']) \n",
    "follower_graph.to_csv('follower_graph.csv', index=False)\n",
    "follower_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion:\n",
    "As is shown above, it takes about **1.22 sec** to find the top 10 hashtags using map reduce approach in Python, while it only takes **0.71 sec** using Unix command. In this question, I solved it in different ways when using map reduce approach and Unix command. As for map reduce, I used the same algorithm as question 1. However, for Unix command, I used \"awk\" command to sort each line into ascending order at the begining. By doing so, if two users is pair of reciprocal follower, their ids will appear twice in the output file. Finally, by using \"sort\" command, we can easily find out pairs that are reciprocal followers. I think this method is faster than map reduce approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Finding Friends of Friends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv file\n",
    "import pandas as pd\n",
    "\n",
    "edges_orig = pd.read_csv(\"./Twitter-dataset/data/edges.csv\")\n",
    "follower_graph = pd.read_csv('follower_graph.csv')\n",
    "edges = edges_orig.head(500000)\n",
    "edges_test = edges_orig.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = list(map(list, follower_graph.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_edges = combiner_reciprocal(mapper_reciprocal(edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8762940, 8762941, 688136, 8762942]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mapper_findFriends(userID, group):\n",
    "    if userID in group:\n",
    "        return group[userID]\n",
    "\n",
    "# Example;\n",
    "mapper_findFriends(1, groups_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mapper_commonFriends(list1, list2):\n",
    "    return list(set(list1).intersection(list2))\n",
    "\n",
    "# Example;\n",
    "mapper_commonFriends([1,2,3,4,5],[2,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reducer_numOfFriends(list1, list2):\n",
    "    common = list(set(list1).intersection(list2))\n",
    "    return len(common)\n",
    "\n",
    "# Example;\n",
    "reducer_numOfFriends([1,2,3,4,5],[2,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([3682, 5276], 714),\n",
       " ([5276, 3682], 714),\n",
       " ([40704, 40997], 402),\n",
       " ([40997, 40704], 402),\n",
       " ([40997, 41039], 360),\n",
       " ([41039, 40997], 360),\n",
       " ([23503, 41422], 352),\n",
       " ([41422, 23503], 352),\n",
       " ([60887, 70696], 332),\n",
       " ([70696, 60887], 332),\n",
       " ([135546, 135684], 282),\n",
       " ([135684, 135546], 282),\n",
       " ([70696, 70772], 259),\n",
       " ([70772, 70696], 259),\n",
       " ([40704, 41039], 252),\n",
       " ([41039, 40704], 252),\n",
       " ([13232, 63255], 236),\n",
       " ([63255, 13232], 236),\n",
       " ([32173, 32452], 194),\n",
       " ([32452, 32173], 194)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def execute_commonFriends(edgesGraph, followerGraph, groups):\n",
    "    output = []\n",
    "    for pair in followerGraph:\n",
    "#         print(pair)\n",
    "        userID = pair[0]\n",
    "        follerID = pair[1]\n",
    "        friendOfUser = mapper_findFriends(userID, groups)\n",
    "        friendOfFoller = mapper_findFriends(follerID, groups)\n",
    "        output.append((pair, reducer_numOfFriends(friendOfUser,friendOfFoller)))\n",
    "    return output\n",
    "                      \n",
    "output = execute_commonFriends(edges, pairs, groups_edges)\n",
    "output = sorted(output, key = lambda x: x[1], reverse = True)\n",
    "output[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
